import { ChatOpenAI } from '@langchain/openai';
import type { BaseChatModel } from '@langchain/core/language_models/chat_models';
import type { Embeddings } from '@langchain/core/embeddings';
import {
  ChatPromptTemplate,
  MessagesPlaceholder,
  PromptTemplate,
} from '@langchain/core/prompts';
import {
  RunnableLambda,
  RunnableMap,
  RunnableSequence,
} from '@langchain/core/runnables';
import { BaseMessage } from '@langchain/core/messages';
import { StringOutputParser } from '@langchain/core/output_parsers';
import LineListOutputParser from '../lib/outputParsers/listLineOutputParser';
import LineOutputParser from '../lib/outputParsers/lineOutputParser';
import { getDocumentsFromLinks } from '../utils/documents';
import { Document } from 'langchain/document';
import { searchSearxng } from '../lib/searxng';
import path from 'path';
import fs from 'fs';
import computeSimilarity from '../utils/computeSimilarity';
import formatChatHistoryAsString from '../utils/formatHistory';
import eventEmitter from 'events';
import { StreamEvent } from '@langchain/core/tracers/log_stream';
import { IterableReadableStream } from '@langchain/core/utils/stream';
import handleImageSearch from '../chains/imageSearchAgent';
import handleExpertSearch from '../chains/expertSearchAgent';
import { Chroma } from '@langchain/community/vectorstores/chroma';
import { RAGDocumentChain } from '../chains/rag_document_upload';
import { SearxngSearchOptions } from '../lib/searxng';
import { ChromaClient } from 'chromadb';
import { OpenAIEmbeddings } from '@langchain/openai';
import { EventEmitter } from 'events';
import { MemoryVectorStore } from "langchain/vectorstores/memory";

export interface MetaSearchAgentType {
  initialize: (embeddings: Embeddings) => Promise<void>;
  searchAndAnswer: (
    message: string,
    history: BaseMessage[],
    llm: BaseChatModel,
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    fileIds: string[],
  ) => Promise<eventEmitter>;
}

interface Config {
  activeEngines: string[];
  queryGeneratorPrompt: string;
  responsePrompt: string;
  rerank: boolean;
  rerankThreshold: number;
  searchWeb: boolean;
  summarizer: boolean;
  searchDatabase: boolean;
  provider?: string;
  model?: string;
  customOpenAIBaseURL?: string;
  customOpenAIKey?: string;
}

type BasicChainInput = {
  chat_history: BaseMessage[];
  query: string;
};

interface SearchResponse {
  text: string;
  sources: Array<{
    title: string;
    content: string;
    url?: string;
    source?: string;
  }>;
  illustrationImage?: string;
}

// Ajouter l'interface pour les m√©tadonn√©es des documents
interface DocumentMetadata {
  title?: string;
  source?: string;
  fileId?: string;
  url?: string;  // Ajout de l'url optionnelle
}

interface SearchResult {
  pageContent: string;
  metadata: {
    score?: number;
    title?: string;
    [key: string]: any;
  };
}

export class MetaSearchAgent implements MetaSearchAgentType {
  private config: Config;
  private strParser = new StringOutputParser();
  private fileIds: string[];
  private memoryStore: MemoryVectorStore;

  constructor(config: Config) {
    this.config = config;
    this.fileIds = [];
  }

  async initialize(embeddings: Embeddings) {
    try {
      if (!this.memoryStore) {
        console.log("üîÑ Initialisation du memory store...");
        this.memoryStore = new MemoryVectorStore(embeddings);
        await this.memoryStore.addDocuments([{
          pageContent: "Initialisation du memory store",
          metadata: { timestamp: Date.now() }
        }]);
        console.log("‚úÖ Memory store initialis√© avec succ√®s");
      }
    } catch (error) {
      console.error("‚ùå Erreur lors de l'initialisation du memory store:", error);
      throw error;
    }
  }

  private async enrichWithMemory(message: string, embeddings: Embeddings): Promise<string> {
    try {
      if (!this.memoryStore) {
        await this.initialize(embeddings);
      }
      await this.memoryStore.addDocuments([{
        pageContent: message,
        metadata: { timestamp: Date.now() }
      }]);
      const results = await this.memoryStore.similaritySearch(message, 2);
      return results.map(doc => doc.pageContent).join('\n');
    } catch (error) {
      console.error("Erreur m√©moire:", error);
      return '';
    }
  }

  private async createSearchRetrieverChain(llm: BaseChatModel) {
    (llm as unknown as ChatOpenAI).temperature = 0;

    return RunnableSequence.from([
      PromptTemplate.fromTemplate(this.config.queryGeneratorPrompt),
      llm,
      this.strParser,
      RunnableLambda.from(async (input: string) => {
        const linksOutputParser = new LineListOutputParser({
          key: 'links',
        });

        const questionOutputParser = new LineOutputParser({
          key: 'question',
        });

        const links = await linksOutputParser.parse(input);
        let question = this.config.summarizer
          ? await questionOutputParser.parse(input)
          : input;

        if (question === 'not_needed') {
          return { query: '', docs: [] };
        }

        let documents: Document[] = [];

        // Recherche web si activ√©e
        if (this.config.searchWeb) {
          const res = await searchSearxng(question, {
            language: 'fr',
            engines: this.config.activeEngines,
          });

          documents = res.results.map(
            (result) =>
              new Document({
                pageContent: result.content,
                metadata: {
                  title: result.title,
                  url: result.url,
                  type: 'web',
                  ...(result.img_src && { img_src: result.img_src }),
                },
              }),
          );
        }

        // Recherche d'experts si activ√©e
        if (this.config.searchDatabase) {
          try {
            console.log("üîç Recherche d'experts...");
            const expertResults = await handleExpertSearch(
              {
                query: question,
                chat_history: [],
                messageId: 'search_' + Date.now(),
                chatId: 'chat_' + Date.now()
              },
              llm
            );

            console.log("üîç Experts trouv√©s:", expertResults.experts.length);
            const expertDocs = expertResults.experts.map(expert => 
              new Document({
                pageContent: `Expert: ${expert.prenom} ${expert.nom}
                Sp√©cialit√©: ${expert.specialite}
                Ville: ${expert.ville}
                Tarif: ${expert.tarif}‚Ç¨
                Expertises: ${expert.expertises}
                Services: ${JSON.stringify(expert.services)}
                ${expert.biographie}`,
                metadata: {
                  type: 'expert',
                  expert: true,
                  expertData: expert,
                  title: `${expert.specialite} - ${expert.ville}`,
                  url: `/expert/${expert.id_expert}`,
                  image_url: expert.image_url
                }
              })
            );

            documents = [...expertDocs, ...documents];
          } catch (error) {
            console.error("Erreur lors de la recherche d'experts:", error);
          }
        }

        // Trier pour mettre les experts en premier
        documents.sort((a, b) => {
          if (a.metadata?.type === 'expert' && b.metadata?.type !== 'expert') return -1;
          if (a.metadata?.type !== 'expert' && b.metadata?.type === 'expert') return 1;
          return 0;
        });

        return { query: question, docs: documents };
      }),
    ]);
  }

  private async loadUploadedDocuments(fileIds: string[]): Promise<Document[]> {
    console.log("üìÇ Chargement des documents:", fileIds);
    const docs: Document[] = [];
    
    for (const fileId of fileIds) {
      try {
        const filePath = path.join(process.cwd(), 'uploads', fileId);
        const contentPath = `${filePath}-extracted.json`;
        const embeddingsPath = `${filePath}-embeddings.json`;
        
        if (!fs.existsSync(contentPath)) {
          throw new Error(`Fichier non trouv√©: ${contentPath}`);
        }

        // Charger le contenu et les embeddings pr√©-calcul√©s
        const content = JSON.parse(fs.readFileSync(contentPath, 'utf8'));
        const embeddingsData = fs.existsSync(embeddingsPath) 
          ? JSON.parse(fs.readFileSync(embeddingsPath, 'utf8'))
          : null;
        
        if (!content.contents || !Array.isArray(content.contents)) {
          throw new Error(`Structure de contenu invalide pour ${fileId}`);
        }

        // Calculer le nombre de chunks par page
        const chunksPerPage = Math.ceil(content.contents.length / (content.pageCount || 10));
        
        content.contents.forEach((chunk: any, index: number) => {
          const pageNumber = Math.floor(index / chunksPerPage) + 1;
          const doc = new Document({
            pageContent: typeof chunk === 'string' ? chunk : chunk.content,
            metadata: {
              ...(typeof chunk === 'object' ? chunk.metadata : {}),
              source: fileId,
              title: content.title || 'Document sans titre',
              pageNumber: pageNumber,
              chunkIndex: index,
              totalChunks: content.contents.length,
              type: 'uploaded',
              embedding: embeddingsData?.embeddings[index]?.vector,
              searchText: (typeof chunk === 'string' ? chunk : chunk.content)
                .substring(0, 100)
                .replace(/[\n\r]+/g, ' ')
                .trim()
            }
          });
          docs.push(doc);
        });

        console.log(`üìë Documents charg√©s depuis ${fileId}:`, docs.length);
      } catch (error) {
        console.error(`‚ùå Erreur lors du chargement du fichier ${fileId}:`, error);
      }
    }

    return docs;
  }

  private async createAnsweringChain(
    llm: BaseChatModel,
    fileIds: string[],
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
  ) {
    return RunnableSequence.from([
      RunnableMap.from({
        query: (input: BasicChainInput) => input.query,
        chat_history: (input: BasicChainInput) => input.chat_history,
        docs: RunnableLambda.from(async (input: BasicChainInput) => {
          console.log("D√©but de la recherche avec contexte enrichi...");
          let docs: Document[] = [];

          // R√©cup√©rer le contexte historique
          const memoryContext = await this.getRelevantContext(input.query);
          console.log("üí≠ Contexte historique pour la recherche:", memoryContext);

          // Enrichir la requ√™te avec le contexte
          const enrichedQuery = `
            Contexte pr√©c√©dent:
            ${memoryContext}
            
            Question actuelle:
            ${input.query}
          `;

          // 1. D'abord chercher dans les documents upload√©s avec le contexte enrichi
          if (fileIds.length > 0) {
            try {
              const uploadedDocs = await this.loadUploadedDocuments(fileIds);
              console.log("üìö Documents upload√©s charg√©s:", uploadedDocs.length);

              const ragChain = new RAGDocumentChain();
              await ragChain.initializeVectorStoreFromDocuments(uploadedDocs, embeddings);
              
              const searchChain = ragChain.createSearchChain(llm);
              const relevantDocs = await searchChain.invoke({
                query: enrichedQuery,
                chat_history: input.chat_history,
                type: 'specific'
              });

              docs = uploadedDocs.map(doc => ({
                ...doc,
                metadata: {
                  ...doc.metadata,
                  score: 0.8
                }
              }));

              console.log("üìÑ Documents pertinents trouv√©s:", docs.length);
            } catch (error) {
              console.error("‚ùå Erreur lors de la recherche dans les documents:", error);
            }
          }

          // 2. Ensuite chercher les experts si pertinent
          if (this.config.searchDatabase) {
            try {
              console.log("üë• Recherche d'experts...");
              const expertResults = await handleExpertSearch(
                {
                  query: input.query,
                  chat_history: input.chat_history,
                  messageId: 'search_' + Date.now(),
                  chatId: 'chat_' + Date.now()
                },
                llm
              );
              
              if (expertResults.experts.length > 0) {
                const expertDocs = this.convertExpertsToDocuments(expertResults.experts);
                docs = [...docs, ...expertDocs];
              }
            } catch (error) {
              console.error("‚ùå Erreur lors de la recherche d'experts:", error);
            }
          }

          // 3. Enfin, compl√©ter avec la recherche web si n√©cessaire et si peu de r√©sultats
          if (this.config.searchWeb && docs.length < 3) {
            try {
              const webResults = await this.performWebSearch(input.query);
              docs = [...docs, ...webResults];
            } catch (error) {
              console.error("‚ùå Erreur lors de la recherche web:", error);
            }
          }

          console.log("üîç DEBUG - Avant appel rerankDocs - Mode:", optimizationMode, "Query:", input.query);
          return this.rerankDocs(
            enrichedQuery,
            docs,
            fileIds,
            embeddings,
            optimizationMode,
            llm
          );
        }).withConfig({ runName: 'FinalSourceRetriever' }),
      }),

      RunnableMap.from({
        query: (input) => input.query,
        chat_history: (input) => input.chat_history,
        date: () => new Date().toISOString(),
        context: (input) => {
          console.log("Pr√©paration du contexte...");
          return this.processDocs(input.docs);
        },
        docs: (input) => input.docs,
      }),

      ChatPromptTemplate.fromMessages([
        ['system', this.config.responsePrompt],
        new MessagesPlaceholder('chat_history'),
        ['user', '{context}\n\n{query}'],
      ]),
      llm,
      this.strParser,
    ]).withConfig({ runName: 'FinalResponseGenerator' });
  }

  private convertExpertsToDocuments(experts: any[]) {
    return experts.map(expert => 
      new Document({
        pageContent: `Expert: ${expert.prenom} ${expert.nom}
        Sp√©cialit√©: ${expert.specialite}
        Ville: ${expert.ville}
        Tarif: ${expert.tarif}‚Ç¨
        Expertises: ${expert.expertises}
        Services: ${JSON.stringify(expert.services)}
        ${expert.biographie}`,
        metadata: {
          type: 'expert',
          expert: true,
          expertData: expert,
          title: `${expert.specialite} - ${expert.ville}`,
          url: `/expert/${expert.id_expert}`,
          image_url: expert.image_url
        }
      })
    );
  }

  private async performWebSearch(query: string) {
    const res = await searchSearxng(query, {
      language: 'fr',
      engines: this.config.activeEngines,
    });

    return res.results.map(result =>
      new Document({
        pageContent: result.content,
        metadata: {
          title: result.title,
          url: result.url,
          type: 'web',
          ...(result.img_src && { img_src: result.img_src }),
        },
      })
    );
  }

  private processDocs(docs: Document[]) {
    // Trier les documents par score si disponible
    const sortedDocs = docs.sort((a, b) => 
      (b.metadata?.score || 0) - (a.metadata?.score || 0)
    );

    // Limiter √† 5 documents maximum
    const limitedDocs = sortedDocs.slice(0, 5);

    // Limiter la taille de chaque document √† 1000 caract√®res
    return limitedDocs
      .map((doc, index) => {
        const content = doc.pageContent.length > 1000 
          ? doc.pageContent.substring(0, 1000) + "..."
          : doc.pageContent;
          
        return `${content} [${index + 1}]`;
      })
      .join('\n\n');
  }

  private async handleStream(
    stream: IterableReadableStream<StreamEvent>,
    emitter: eventEmitter,
  ) {
    for await (const event of stream) {
      if (
        event.event === 'on_chain_end' &&
        event.name === 'FinalSourceRetriever'
      ) {
        const sources = event.data.output;
        
        // Normaliser les sources pour le frontend
        const normalizedSources = sources?.map(source => {
          const isUploadedDoc = source.metadata?.type === 'uploaded';
          const isExpert = source.metadata?.type === 'expert';
          const pageNumber = source.metadata?.pageNumber || 1;
          const sourceId = source.metadata?.source;
          
          // Construire l'URL selon le type de source
          let url;
          if (isUploadedDoc && sourceId) {
            url = `/api/uploads/${sourceId}/content?page=${pageNumber}`;
          } else if (isExpert) {
            url = source.metadata?.url;
          } else if (source.metadata?.type === 'web') {
            url = source.metadata?.url;
          }
          
          // Construire un titre descriptif
          let title = source.metadata?.title || '';
          if (isUploadedDoc && title) {
            title = `${title} - Page ${pageNumber}`;
          } else if (isExpert) {
            title = source.metadata?.displayTitle || title;
          }
          
          // Limiter la taille du contenu pour √©viter les erreurs de payload
          const limitedContent = source.pageContent?.substring(0, 1000) || '';
          
          return {
            pageContent: limitedContent,
            metadata: {
              title: title,
              type: source.metadata?.type || 'web',
              url: url,
              source: sourceId,
              pageNumber: pageNumber,
              searchText: source.metadata?.searchText?.substring(0, 200) || limitedContent.substring(0, 200),
              expertData: source.metadata?.expertData,
              illustrationImage: source.metadata?.illustrationImage,
              imageTitle: source.metadata?.imageTitle,
              favicon: source.metadata?.favicon,
              linkText: source.metadata?.linkText,
              expertName: source.metadata?.expertName
            }
          };
        }) || [];

        console.log("üîç Sources normalis√©es:", normalizedSources.length);
        
        emitter.emit(
          'data',
          JSON.stringify({ 
            type: 'sources', 
            data: normalizedSources,
            illustrationImage: normalizedSources[0]?.metadata?.illustrationImage || null,
            imageTitle: normalizedSources[0]?.metadata?.imageTitle || null
          })
        );
      }
      if (
        event.event === 'on_chain_stream' &&
        event.name === 'FinalResponseGenerator'
      ) {
        emitter.emit(
          'data',
          JSON.stringify({ type: 'response', data: event.data.chunk })
        );
      }
      if (
        event.event === 'on_chain_end' &&
        event.name === 'FinalResponseGenerator'
      ) {
        emitter.emit('end');
      }
    }
  }

  private async searchExperts(
    query: string, 
    embeddings: Embeddings,
    llm: BaseChatModel
  ): Promise<SearchResult[]> {
    try {
      console.log("üë• Recherche d'experts pour:", query);
      const expertResults = await handleExpertSearch(
        {
          query,
          chat_history: [],
          messageId: 'search_' + Date.now(),
          chatId: 'chat_' + Date.now()
        },
        llm
      );

      return expertResults.experts.map(expert => ({
        pageContent: `Expert: ${expert.prenom} ${expert.nom}
        Sp√©cialit√©: ${expert.specialite}
        Ville: ${expert.ville}
        Tarif: ${expert.tarif}‚Ç¨
        Expertises: ${expert.expertises}
        Services: ${JSON.stringify(expert.services)}
        ${expert.biographie}`,
        metadata: {
          type: 'expert',
          expert: true,
          expertData: expert,
          title: `${expert.prenom} ${expert.nom} - ${expert.specialite}`,
          url: `/expert/${expert.id_expert}`,
          image_url: expert.image_url,
          score: 0.6 // Score moyen pour les experts
        }
      }));
    } catch (error) {
      console.error("‚ùå Erreur lors de la recherche d'experts:", error);
      return [];
    }
  }

  private async searchWeb(query: string): Promise<SearchResult[]> {
    try {
      console.log("üåê Recherche web pour:", query);
      const res = await searchSearxng(query, {
        language: 'fr',
        engines: this.config.activeEngines,
      });

      return res.results.map(result => ({
        pageContent: result.content,
        metadata: {
          title: result.title,
          url: result.url,
          type: 'web',
          score: 0.4, // Score plus faible pour les r√©sultats web
          ...(result.img_src && { img_src: result.img_src }),
        }
      }));
    } catch (error) {
      console.error("‚ùå Erreur lors de la recherche web:", error);
      return [];
    }
  }

  private async rerankDocs(
    query: string,
    docs: Document[],
    fileIds: string[],
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    llm: BaseChatModel
  ) {
    console.log("üîç Mode d'optimisation:", optimizationMode);
    console.log("üîç Query pour la recherche d'image:", query);
    
    if (optimizationMode === 'balanced' || optimizationMode === 'quality') {
      console.log("üîç D√©marrage de la recherche d'images...");
      try {
        console.log("üîç Appel de handleImageSearch avec la query:", query);
        const images = await handleImageSearch(
          {
            query,
            chat_history: [],
          },
          llm
        );
        console.log("üîç R√©sultat brut de handleImageSearch:", JSON.stringify(images, null, 2));
        console.log("üîç Images trouv√©es:", images?.length);
        
        if (images && images.length > 0) {
          console.log("üîç Premi√®re image trouv√©e:", {
            src: images[0].img_src,
            title: images[0].title,
            url: images[0].url
          });
          return docs.slice(0, 15).map(doc => ({
            ...doc,
            metadata: {
              ...doc.metadata,
              illustrationImage: images[0].img_src,
              title: images[0].title
            }
          }));
        } else {
          console.log("‚ö†Ô∏è Aucune image trouv√©e dans le r√©sultat");
        }
      } catch (error) {
        console.error("‚ùå Erreur d√©taill√©e lors de la recherche d'image:", {
          message: error.message,
          stack: error.stack
        });
      }
    } else {
      console.log("üîç Mode speed: pas de recherche d'images");
    }

    return docs.slice(0, 15);
  }

  private async updateMemoryStore(message: string, history: BaseMessage[]) {
    try {
      if (!this.memoryStore) {
        throw new Error("Memory store not initialized");
      }
      
      // Cr√©er un document avec le contexte actuel et sa structure
      const contextDoc = {
        pageContent: `Question: ${message}\nContext: ${history.map(m => 
          `${m._getType()}: ${m.content}`).join('\n')}`,
        metadata: { 
          timestamp: Date.now(),
          themes: this.extractThemes(message + ' ' + history.map(m => m.content).join(' ')),
          type: 'conversation'
        }
      };

      console.log("üíæ Ajout √† la m√©moire:", contextDoc);
      await this.memoryStore.addDocuments([contextDoc]);
      console.log("‚úÖ M√©moire mise √† jour avec succ√®s");
    } catch (error) {
      console.error("‚ùå Erreur lors de la mise √† jour de la m√©moire:", error);
    }
  }

  private async getRelevantContext(message: string): Promise<string> {
    try {
      if (!this.memoryStore) {
        throw new Error("Memory store not initialized");
      }
      console.log("üîç Recherche dans la m√©moire pour:", message);
      
      const results = await this.memoryStore.similaritySearch(message, 3);
      console.log("üìö Contexte trouv√© dans la m√©moire:", results);
      return results.map(doc => doc.pageContent).join('\n');
    } catch (error) {
      console.error("‚ùå Erreur lors de la r√©cup√©ration du contexte:", error);
      return '';
    }
  }

  private extractThemes(context: string): string[] {
    const commonThemes = ['sas', 'entreprise', 'cr√©ation', 'chomage', 'juridique', 'financement'];
    return commonThemes.filter(theme => 
      context.toLowerCase().includes(theme.toLowerCase())
    );
  }

  private async analyzeConversationContext(
    message: string,
    history: BaseMessage[],
    llm: BaseChatModel
  ): Promise<{ context: string; relevance: number }> {
    try {
      const formattedHistory = formatChatHistoryAsString(history);
      
      const analysis = await llm.invoke(`
        Analysez cette conversation en profondeur en donnant une importance particuli√®re aux 3 derniers √©changes.
        Assurez-vous de maintenir la coh√©rence du contexte entre les questions.
        
        Historique de la conversation:
        ${formattedHistory}

        Nouvelle question: "${message}"

        Instructions sp√©cifiques:
        1. Identifiez les th√®mes r√©currents des 3 derniers √©changes
        2. Notez les contraintes ou conditions mentionn√©es pr√©c√©demment qui restent pertinentes
        3. √âvaluez comment la nouvelle question s'inscrit dans la continuit√© des √©changes

        R√©pondez au format JSON:
        {
          "mainTopic": "sujet principal actuel",
          "recentContext": {
            "lastThemes": ["th√®mes des 3 derniers √©changes"],
            "activeConstraints": ["contraintes toujours actives"],
            "continuityScore": <0.0 √† 1.0>
          },
          "contextualFactors": {
            "financial": ["facteurs financiers"],
            "legal": ["aspects juridiques"],
            "administrative": ["aspects administratifs"]
          },
          "impactAnalysis": {
            "primary": "impact principal",
            "secondary": ["impacts secondaires"],
            "constraints": ["contraintes identifi√©es"]
          },
          "relevanceScore": <0.0 √† 1.0>
        }
      `);

      const result = JSON.parse(String(analysis.content));
      
      // Construction d'un contexte enrichi qui met l'accent sur la continuit√©
      const enrichedContext = `
        Contexte principal: ${result.mainTopic}
        Th√®mes r√©cents: ${result.recentContext.lastThemes.join(', ')}
        Contraintes actives: ${result.recentContext.activeConstraints.join(', ')}
        Facteurs impactants: ${result.contextualFactors.financial.join(', ')}
        Implications l√©gales: ${result.contextualFactors.legal.join(', ')}
        Impact global: ${result.impactAnalysis.primary}
        Contraintes √† consid√©rer: ${result.impactAnalysis.constraints.join(', ')}
      `.trim();

      // Ajuster le score de pertinence en fonction de la continuit√©
      const adjustedRelevance = (result.relevanceScore + result.recentContext.continuityScore) / 2;

      return {
        context: enrichedContext,
        relevance: adjustedRelevance
      };
    } catch (error) {
      console.error("Erreur lors de l'analyse du contexte:", error);
      return { context: '', relevance: 0 };
    }
  }

  async searchAndAnswer(
    message: string,
    history: BaseMessage[],
    llm: BaseChatModel,
    embeddings: Embeddings,
    optimizationMode: 'speed' | 'balanced' | 'quality',
    fileIds: string[],
  ) {
    const effectiveMode = 'balanced';
    const emitter = new EventEmitter();

    try {
      // S'assurer que le memoryStore est initialis√©
      if (!this.memoryStore) {
        console.log("üîÑ Initialisation du memory store dans searchAndAnswer...");
        try {
          await this.initialize(embeddings);
          if (!this.memoryStore) {
            throw new Error("Memory store initialization failed");
          }
        } catch (error) {
          console.error("‚ùå Erreur lors de l'initialisation du memory store:", error);
          throw error;
        }
      }

      // Analyser le contexte de la conversation
      const conversationContext = await this.analyzeConversationContext(message, history, llm);
      console.log("üß† Analyse du contexte:", conversationContext);

      // Mettre √† jour la m√©moire avec le contexte actuel
      await this.updateMemoryStore(message, history);

      // R√©cup√©rer le contexte pertinent de la m√©moire
      const memoryContext = await this.getRelevantContext(message);
      console.log("üí≠ Contexte m√©moire r√©cup√©r√©:", memoryContext);

      // Enrichir le message avec le contexte historique
      const enrichedMessage = `
        Contexte pr√©c√©dent:
        ${memoryContext}
        
        Contexte actuel:
        ${conversationContext.context}
        
        Question actuelle:
        ${message}
      `;

      // Analyse sophistiqu√©e de la requ√™te avec LLM
      const queryAnalysis = await llm.invoke(`
        En tant qu'expert en analyse de requ√™tes, examine cette demande dans son contexte complet.
        
        ${enrichedMessage}

        Documents disponibles: ${fileIds.length > 0 ? "Oui" : "Non"}

        Analyse et r√©ponds au format JSON:
        {
          "primaryIntent": "DOCUMENT_QUERY" | "WEB_SEARCH" | "EXPERT_ADVICE" | "HYBRID",
          "requiresDocumentSearch": <boolean>,
          "requiresWebSearch": <boolean>,
          "requiresExpertSearch": <boolean>,
          "documentRelevance": <0.0 √† 1.0>,
          "contextRelevance": ${conversationContext.relevance},
          "reasoning": "<courte explication>"
        }`);

      const analysis = JSON.parse(String(queryAnalysis.content));
      console.log("üéØ Analyse de la requ√™te enrichie:", analysis);

      // 1. Analyse des documents upload√©s avec RAG
      const uploadedDocs = await this.loadUploadedDocuments(fileIds);
      console.log("üìö Documents upload√©s charg√©s:", uploadedDocs.length);
      
      if (uploadedDocs.length > 0) {
        // Cr√©ation du vectorStore temporaire pour les documents
        const vectorStore = await Chroma.fromDocuments(uploadedDocs, embeddings, {
          collectionName: "temp_docs",
          url: "http://chroma:8000",
          numDimensions: 1536
        });

        // Recherche s√©mantique sans filtre pour l'instant
        const relevantDocs = await vectorStore.similaritySearch(message, 5);
        
        console.log("üìÑ Documents pertinents trouv√©s:", relevantDocs.length);

        // Extraction du contexte pour enrichir la recherche
        const documentContext = relevantDocs
          .map(doc => doc.pageContent)
          .join("\n")
          .substring(0, 500);
        
        const documentTitle = uploadedDocs[0]?.metadata?.title || "";
        const enrichedQuery = `${message} ${documentTitle} ${documentContext}`;

        // 2. Recherche d'experts en BDD
        const expertResults = await this.searchExperts(message, embeddings, llm);
        
        // 3. Recherche web compl√©mentaire avec le contexte enrichi
        const webResults = await this.searchWeb(enrichedQuery);

        // Combinaison des r√©sultats avec les scores appropri√©s
        const combinedResults = [
          ...relevantDocs.map(doc => ({
            ...doc,
            metadata: {
              ...doc.metadata,
              score: 0.8 // Score √©lev√© pour les documents upload√©s
            }
          })),
          ...expertResults.map(expert => ({
            ...expert,
            metadata: {
              ...expert.metadata,
              score: 0.6 // Score moyen pour les experts
            }
          })),
          ...webResults.map(web => ({
            ...web,
            metadata: {
              ...web.metadata,
              score: 0.4 // Score plus faible pour les r√©sultats web
            }
          }))
        ];

        // Tri et s√©lection des meilleurs r√©sultats
        const finalResults = await this.rerankDocs(
          message,
          combinedResults,
          fileIds,
          embeddings,
          effectiveMode,
          llm
        );

        // Cr√©ation de la cha√Æne de r√©ponse
        const answeringChain = await this.createAnsweringChain(
          llm,
          fileIds,
          embeddings,
          effectiveMode
        );

        const stream = answeringChain.streamEvents(
          {
            chat_history: history,
            query: `${message}\n\nContexte pertinent:\n${finalResults.map(doc => doc.pageContent).join('\n\n')}`
          },
          {
            version: 'v1'
          }
        );

        this.handleStream(stream, emitter);
      } else {
        // Fallback sans documents upload√©s
        const answeringChain = await this.createAnsweringChain(
          llm,
          fileIds,
          embeddings,
          effectiveMode
        );

        const stream = answeringChain.streamEvents(
          {
            chat_history: history,
            query: message
          },
          {
            version: 'v1'
          }
        );

        this.handleStream(stream, emitter);
      }
    } catch (error) {
      console.error("‚ùå Erreur:", error);
      // Fallback en mode standard
      const answeringChain = await this.createAnsweringChain(
        llm,
        fileIds,
        embeddings,
        effectiveMode
      );

      const stream = answeringChain.streamEvents(
        {
          chat_history: history,
          query: message
        },
        {
          version: 'v1'
        }
      );

      this.handleStream(stream, emitter);
    }

    return emitter;
  }
}

export const searchHandlers: Record<string, MetaSearchAgentType> = {
  // ... existing handlers ...
  legal: {
    initialize: async (embeddings: Embeddings) => {
      // Pas besoin d'initialisation sp√©cifique pour le handler legal
    },
    searchAndAnswer: async (
      message,
      history,
      llm,
      embeddings,
      optimizationMode,
      fileIds,
    ) => {
      const emitter = new eventEmitter();

      try {
        const chain = new RAGDocumentChain();
        await chain.initializeVectorStoreFromDocuments(fileIds.map(fileId => new Document({
          pageContent: '',
          metadata: { source: fileId }
        })), embeddings);

        const searchChain = chain.createSearchChain(llm);
        const results = await searchChain.invoke({
          query: message,
          chat_history: history,
          type: 'legal'
        });

        // Convertir le r√©sultat en objet SearchResponse
        const response: SearchResponse = {
          text: results,
          sources: [] // Sources vides par d√©faut
        };

        // √âmettre la r√©ponse
        emitter.emit(
          'data',
          JSON.stringify({
            type: 'response',
            data: response.text,
          })
        );

        emitter.emit('end');
      } catch (error) {
        emitter.emit(
          'error',
          JSON.stringify({
            type: 'error',
            data: error.message,
          })
        );
      }

      return emitter;
    },
  },
  documents: {
    initialize: async (embeddings: Embeddings) => {
      // Pas besoin d'initialisation sp√©cifique pour le handler documents
    },
    searchAndAnswer: async (
      message,
      history,
      llm,
      embeddings,
      optimizationMode,
      fileIds,
    ) => {
      const emitter = new eventEmitter();
      const ragChain = new RAGDocumentChain();

      try {
        const docs = fileIds.map(fileId => {
          const filePath = path.join(process.cwd(), 'uploads', fileId);
          const contentPath = filePath + '-extracted.json';
          const content = JSON.parse(fs.readFileSync(contentPath, 'utf8'));
          return new Document<DocumentMetadata>({
            pageContent: content.contents.join('\n'),
            metadata: {
              title: content.title,
              source: fileId,
            }
          });
        });

        await ragChain.initializeVectorStoreFromDocuments(docs, embeddings);
        const chain = ragChain.createSearchChain(llm);
        const result = await chain.invoke({
          query: message,
          chat_history: history,
          type: 'document_search'
        });

        // Convertir le r√©sultat en objet SearchResponse
        const response: SearchResponse = {
          text: result,
          sources: docs.map(doc => ({
            title: doc.metadata?.title || '',
            content: doc.pageContent,
            source: doc.metadata?.source || 'uploaded_docs'
          }))
        };

        emitter.emit('data', JSON.stringify({
          type: 'response',
          data: response.text
        }));

        emitter.emit('data', JSON.stringify({
          type: 'sources',
          data: response.sources
        }));

        emitter.emit('end');
      } catch (error) {
        emitter.emit('error', JSON.stringify({
          type: 'error',
          data: error.message
        }));
      }

      return emitter;
    }
  },
  uploads: {
    initialize: async (embeddings: Embeddings) => {
      // Pas besoin d'initialisation sp√©cifique pour le handler uploads
    },
    searchAndAnswer: async (
      message,
      history,
      llm,
      embeddings,
      optimizationMode,
      fileIds,
    ) => {
      const emitter = new eventEmitter();

      try {
        // Analyse du type de requ√™te avec LLM pour plus de pr√©cision
        const queryIntent = await llm.invoke(`
          Analysez cette requ√™te et d√©terminez son intention principale :
          1. SUMMARY (demande de r√©sum√© ou synth√®se globale)
          2. ANALYSIS (demande d'analyse ou d'explication)
          3. SPECIFIC (question sp√©cifique sur le contenu)
          4. COMPARE (demande de comparaison)

          Requ√™te : "${message}"
          
          R√©pondez uniquement avec l'intention.
        `);

        const intent = String(queryIntent.content).trim();
        console.log("üéØ Intention d√©tect√©e:", intent);

        // Chargement optimis√© des documents
        const docs = await Promise.all(fileIds.map(async fileId => {
          const filePath = path.join(process.cwd(), 'uploads', fileId);
          const contentPath = `${filePath}-extracted.json`;
          
          if (!fs.existsSync(contentPath)) {
            throw new Error(`Fichier non trouv√©: ${contentPath}`);
          }

          const content = JSON.parse(fs.readFileSync(contentPath, 'utf8'));
          
          // Optimisation : Chunking plus efficace
          const chunkSize = 1000; // Taille optimale pour le traitement
          const overlap = 100; // Chevauchement pour maintenir le contexte
          
          const chunks = [];
          let currentChunk = '';
          let currentSize = 0;
          
          content.contents.forEach((text: string) => {
            currentChunk += text + ' ';
            currentSize += text.length;
            
            if (currentSize >= chunkSize) {
              chunks.push(currentChunk);
              // Garder le chevauchement pour le prochain chunk
              currentChunk = currentChunk.slice(-overlap);
              currentSize = overlap;
            }
          });
          
          if (currentChunk) {
            chunks.push(currentChunk);
          }
          
          return chunks.map((chunk, index) => {
            const pageNumber = Math.floor(index / (chunks.length / (content.pageCount || 1))) + 1;
            
            return new Document({
              pageContent: chunk,
              metadata: {
                title: content.title || 'Document sans titre',
                source: fileId,
                type: 'uploaded',
                url: `/api/uploads/${fileId}/view?page=${pageNumber}`,
                pageNumber: pageNumber,
                chunkIndex: index,
                totalChunks: chunks.length,
                searchText: chunk.substring(0, 100).replace(/[\n\r]+/g, ' ').trim()
              }
            });
          });
        }));

        const flatDocs = docs.flat();
        console.log("üìö Nombre total de chunks:", flatDocs.length);

        const ragChain = new RAGDocumentChain();
        await ragChain.initializeVectorStoreFromDocuments(flatDocs, embeddings);
        const chain = ragChain.createSearchChain(llm);

        // Adaptation de la requ√™te selon l'intention d√©tect√©e par le LLM
        let queryPrompt = message;
        switch(intent) {
          case 'SUMMARY':
            queryPrompt = "Fais un r√©sum√© complet et structur√© de ce document en te concentrant sur les points cl√©s";
            break;
          case 'ANALYSIS':
            queryPrompt = `Analyse en d√©tail les aspects suivants du document concernant : ${message}. Fournis une analyse structur√©e avec des exemples du texte.`;
            break;
          case 'SPECIFIC':
            // Garde la question originale mais ajoute du contexte
            queryPrompt = `En te basant sur le contenu du document, r√©ponds pr√©cis√©ment √† cette question : ${message}`;
            break;
          case 'COMPARE':
            queryPrompt = `Compare et analyse en d√©tail les diff√©rents aspects concernant : ${message}. Structure ta r√©ponse par points de comparaison.`;
            break;
        }

        // Stream optimis√© avec √©mission rapide des sources
        const stream = await chain.streamEvents(
          {
            query: queryPrompt,
            chat_history: history,
            type: intent.toLowerCase()
          },
          { version: 'v1' }
        );

        // Gestion optimis√©e du stream
        let sourcesEmitted = false;
        for await (const event of stream) {
          if (event.event === 'on_chain_stream') {
            emitter.emit(
              'data',
              JSON.stringify({
                type: 'response',
                data: event.data.chunk
              })
            );
          }
          
          // √âmettre les sources plus t√¥t dans le processus
          if (!sourcesEmitted && event.event === 'on_chain_start') {
            const sources = flatDocs.slice(0, 5).map(doc => ({
              title: doc.metadata?.title || '',
              content: doc.metadata?.searchText || '',
              url: doc.metadata?.url,
              source: doc.metadata?.source,
              type: 'uploaded',
              pageNumber: doc.metadata?.pageNumber
            }));

            emitter.emit(
              'data',
              JSON.stringify({
                type: 'sources',
                data: sources
              })
            );
            sourcesEmitted = true;
          }

          if (event.event === 'on_chain_end') {
            emitter.emit('end');
          }
        }

      } catch (error) {
        console.error("Erreur lors de la recherche dans les documents:", error);
        emitter.emit('error', JSON.stringify({
          type: 'error',
          data: error.message
        }));
      }

      return emitter;
    }
  }
};

export default MetaSearchAgent;
