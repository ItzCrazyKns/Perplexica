[GENERAL]
SIMILARITY_MEASURE = "cosine" # "cosine" or "dot"
KEEP_ALIVE = "5m" # How long to keep Ollama models loaded into memory. (Instead of using -1 use "-1m")
DEFAULT_CHAT_MODEL = "" # Default chat model to use for any provider - e.g., "llama3.2:latest"
DEFAULT_EMBEDDING_MODEL = "" # Default embedding model to use for any provider - e.g., "mxbai-embed-large:latest"

[MODELS.OPENAI]
API_KEY = ""

[MODELS.GROQ]
API_KEY = ""

[MODELS.ANTHROPIC]
API_KEY = ""

[MODELS.GEMINI]
API_KEY = ""

[MODELS.CUSTOM_OPENAI]
API_KEY = ""
API_URL = ""
MODEL_NAME = ""

[MODELS.OLLAMA]
API_URL = "" # Ollama API URL - http://host.docker.internal:11434

[MODELS.DEEPSEEK]
API_KEY = ""

[MODELS.AIMLAPI]
API_KEY = "" # Required to use AI/ML API chat and embedding models

[MODELS.LM_STUDIO]
API_URL = "" # LM Studio API URL - http://host.docker.internal:1234

[MODELS.LEMONADE]
API_URL = "" # Lemonade API URL - http://host.docker.internal:8000
API_KEY = "" # Optional API key for Lemonade

[API_ENDPOINTS]
SEARXNG = "" # SearxNG API URL - http://localhost:32768
