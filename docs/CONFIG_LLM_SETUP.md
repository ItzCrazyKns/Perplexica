## H∆∞·ªõng d·∫´n c·∫•u h√¨nh LLM cho Perplexica (config.toml)

‚ö†Ô∏è **B·∫ÆT BU·ªòC**: Perplexica kh√¥ng th·ªÉ ch·∫°y n·∫øu thi·∫øu config.toml ho·∫∑c kh√¥ng c√≥ API key LLM h·ª£p l·ªá.

---

## T·∫°i sao c·∫ßn config.toml?

Perplexica l√† c√¥ng c·ª• t√¨m ki·∫øm AI-powered c·∫ßn **Large Language Model (LLM)** ƒë·ªÉ:
- Hi·ªÉu c√¢u h·ªèi c·ªßa ng∆∞·ªùi d√πng
- T·∫°o query t√¨m ki·∫øm th√¥ng minh
- T·ªïng h·ª£p k·∫øt qu·∫£ t·ª´ SearXNG
- T·∫°o c√¢u tr·∫£ l·ªùi c√≥ ng·ªØ c·∫£nh

**Kh√¥ng c√≥ LLM API key ‚Üí ·ª©ng d·ª•ng kh√¥ng ho·∫°t ƒë·ªông.**

---

## C√°c b∆∞·ªõc c·∫•u h√¨nh nhanh

### 1) Copy t·ª´ sample

```bash
cp sample.config.toml config.toml
```

### 2) Ch·ªçn LLM provider v√† l·∫•y API key

#### Option 1: Groq (Khuy·∫øn ngh·ªã - Mi·ªÖn ph√≠, nhanh)

1. Truy c·∫≠p: https://console.groq.com/
2. ƒêƒÉng k√Ω t√†i kho·∫£n (mi·ªÖn ph√≠)
3. V√†o **API Keys** ‚Üí **Create API Key**
4. Copy key b·∫Øt ƒë·∫ßu b·∫±ng `gsk_...`

**config.toml:**
```toml
[MODELS.GROQ]
API_KEY = "gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**Models available**: Llama 3.1 70B, Llama 3.1 8B, Mixtral 8x7B, Gemma 2 9B

---

#### Option 2: Google Gemini (Mi·ªÖn ph√≠ tier)

1. Truy c·∫≠p: https://aistudio.google.com/apikey
2. ƒêƒÉng nh·∫≠p Google
3. Click **Get API key** ‚Üí **Create API key**
4. Copy key

**config.toml:**
```toml
[MODELS.GEMINI]
API_KEY = "AIzaSyxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**Models available**: Gemini 1.5 Flash, Gemini 1.5 Pro

---

#### Option 3: OpenAI (Tr·∫£ ph√≠ - ch·∫•t l∆∞·ª£ng cao)

1. Truy c·∫≠p: https://platform.openai.com/api-keys
2. ƒêƒÉng k√Ω v√† n·∫°p credit (t·ªëi thi·ªÉu $5)
3. T·∫°o API key
4. Copy key b·∫Øt ƒë·∫ßu b·∫±ng `sk-proj-...`

**config.toml:**
```toml
[MODELS.OPENAI]
API_KEY = "sk-proj-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**Models available**: GPT-4o, GPT-4o-mini, GPT-4 Turbo, GPT-3.5 Turbo

---

#### Option 4: Anthropic Claude (Tr·∫£ ph√≠)

1. Truy c·∫≠p: https://console.anthropic.com/
2. ƒêƒÉng k√Ω v√† n·∫°p credit
3. V√†o **API Keys** ‚Üí **Create Key**
4. Copy key b·∫Øt ƒë·∫ßu b·∫±ng `sk-ant-...`

**config.toml:**
```toml
[MODELS.ANTHROPIC]
API_KEY = "sk-ant-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**Models available**: Claude 3.5 Sonnet, Claude 3 Opus, Claude 3 Haiku

---

#### Option 5: DeepSeek (R·∫ª - $0.14/1M tokens)

1. Truy c·∫≠p: https://platform.deepseek.com/
2. ƒêƒÉng k√Ω v√† n·∫°p credit (ch·∫•p nh·∫≠n $1)
3. V√†o **API Keys** ‚Üí **Create API Key**
4. Copy key

**config.toml:**
```toml
[MODELS.DEEPSEEK]
API_KEY = "sk-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

**Models available**: DeepSeek Chat, DeepSeek Coder

---

#### Option 6: Custom OpenAI-compatible API

N·∫øu b·∫°n c√≥ API t∆∞∆°ng th√≠ch OpenAI (v√≠ d·ª•: ZhipuAI, Together AI, Fireworks AI...):

**config.toml:**
```toml
[MODELS.CUSTOM_OPENAI]
API_KEY = "your-api-key-here"
API_URL = "https://api.provider.com/v1"
MODEL_NAME = "model-name"
```

V√≠ d·ª• v·ªõi ZhipuAI:
```toml
[MODELS.CUSTOM_OPENAI]
API_KEY = "7864229fc2c1456691354b14fc0bf409.xxxxx"
API_URL = "https://open.bigmodel.cn/api/paas/v4"
MODEL_NAME = "glm-4"
```

---

#### Option 7: Ollama (Self-hosted - Mi·ªÖn ph√≠ ho√†n to√†n)

N·∫øu b·∫°n ch·∫°y Ollama local ho·∫∑c tr√™n server ri√™ng:

**config.toml:**
```toml
[MODELS.OLLAMA]
API_URL = "http://host.docker.internal:11434"  # N·∫øu Ollama ch·∫°y tr√™n host machine
# Ho·∫∑c: "http://your-ollama-server:11434"
```

**L∆∞u √Ω**: C·∫ßn c√†i Ollama v√† pull model tr∆∞·ªõc (v√≠ d·ª•: `ollama pull llama3.1:8b`)

---

### 3) C·∫•u h√¨nh SearXNG endpoint

N·∫øu d√πng Docker Compose (m·∫∑c ƒë·ªãnh):
```toml
[API_ENDPOINTS]
SEARXNG = "http://searxng:8080"
```

N·∫øu SearXNG ch·∫°y ri√™ng:
```toml
[API_ENDPOINTS]
SEARXNG = "http://your-searxng-server:8080"
```

---

### 4) Config.toml t·ªëi thi·ªÉu ho√†n ch·ªânh

```toml
[GENERAL]
SIMILARITY_MEASURE = "cosine"

[MODELS.GROQ]
API_KEY = "gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"

[API_ENDPOINTS]
SEARXNG = "http://searxng:8080"
```

Ho·∫∑c n·∫øu d√πng nhi·ªÅu providers (·ª©ng d·ª•ng s·∫Ω cho ph√©p ch·ªçn):

```toml
[GENERAL]
SIMILARITY_MEASURE = "cosine"

[MODELS.OPENAI]
API_KEY = "sk-proj-xxxxxxxxxxxxxxxx"

[MODELS.GROQ]
API_KEY = "gsk_xxxxxxxxxxxxxxxx"

[MODELS.ANTHROPIC]
API_KEY = "sk-ant-xxxxxxxxxxxxxxxx"

[MODELS.GEMINI]
API_KEY = "AIzaSyxxxxxxxxxxxxxxxx"

[API_ENDPOINTS]
SEARXNG = "http://searxng:8080"
```

---

## Ki·ªÉm tra config.toml

```bash
# ƒê·∫£m b·∫£o c√≥ √≠t nh·∫•t 1 API_KEY kh√¥ng r·ªóng
cat config.toml | grep API_KEY | grep -v '""'

# Output mong mu·ªën (v√≠ d·ª•):
# API_KEY = "gsk_xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx"
```

---

## Deploy config.toml l√™n EC2

### N·∫øu deploy b·∫±ng Docker Compose th·ªß c√¥ng:
```bash
scp -i ~/.ssh/your-key.pem ./config.toml ubuntu@<EC2-IP>:/opt/Perplexica/
ssh -i ~/.ssh/your-key.pem ubuntu@<EC2-IP> "sudo systemctl restart perplexica"
```

### N·∫øu deploy b·∫±ng CloudFormation:
```bash
# Sau khi stack CREATE_COMPLETE
INSTANCE_IP=$(aws cloudformation describe-stacks \
  --stack-name perplexica-prod \
  --query 'Stacks[0].Outputs[?OutputKey==`PublicIP`].OutputValue' \
  --output text)

scp -i ~/.ssh/perplexica-key.pem ./config.toml ubuntu@$INSTANCE_IP:/opt/Perplexica/
ssh -i ~/.ssh/perplexica-key.pem ubuntu@$INSTANCE_IP "sudo systemctl restart perplexica"
```

---

## Troubleshooting

### L·ªói: "No LLM provider configured"
- Ki·ªÉm tra config.toml c√≥ t·ªìn t·∫°i: `ls -la /opt/Perplexica/config.toml`
- Ki·ªÉm tra c√≥ API key: `cat /opt/Perplexica/config.toml | grep API_KEY`
- ƒê·∫£m b·∫£o √≠t nh·∫•t 1 provider c√≥ key h·ª£p l·ªá

### L·ªói: "Invalid API key"
- Ki·ªÉm tra key kh√¥ng b·ªã th·ª´a/thi·∫øu k√Ω t·ª±
- Ki·ªÉm tra key ch∆∞a h·∫øt h·∫°n/b·ªã revoke
- Th·ª≠ t·∫°o key m·ªõi t·ª´ console provider

### L·ªói: "Rate limit exceeded"
- Groq free tier: 30 requests/minute
- OpenAI: t√πy plan (tier 1: 500 RPM)
- ƒê·ª£i 1 ph√∫t ho·∫∑c n√¢ng c·∫•p plan

### L·ªói: "Cannot connect to SearXNG"
- Ki·ªÉm tra SearXNG container ƒëang ch·∫°y: `docker ps | grep searxng`
- Ki·ªÉm tra network: `docker network ls | grep perplexica`
- N·∫øu SearXNG external, ki·ªÉm tra firewall/URL

---

## So s√°nh LLM providers

| Provider | Mi·ªÖn ph√≠? | Gi√° (n·∫øu tr·∫£ ph√≠) | T·ªëc ƒë·ªô | Ch·∫•t l∆∞·ª£ng | Khuy·∫øn ngh·ªã |
|----------|-----------|-------------------|--------|------------|-------------|
| **Groq** | ‚úÖ C√≥ (v·ªõi gi·ªõi h·∫°n) | N/A | ‚ö° R·∫•t nhanh | ‚≠ê‚≠ê‚≠ê‚≠ê T·ªët | **T·ªët nh·∫•t cho free** |
| **Gemini** | ‚úÖ C√≥ (free tier) | $0.35/1M tokens | üöÄ Nhanh | ‚≠ê‚≠ê‚≠ê‚≠ê T·ªët | **T·ªët cho free** |
| **DeepSeek** | ‚ùå Kh√¥ng | $0.14/1M tokens | üöÄ Nhanh | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê R·∫•t t·ªët | **R·∫ª nh·∫•t tr·∫£ ph√≠** |
| **OpenAI** | ‚ùå Kh√¥ng | $0.15‚Äì$10/1M | üê¢ Trung b√¨nh | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Xu·∫•t s·∫Øc | Ch·∫•t l∆∞·ª£ng cao |
| **Anthropic** | ‚ùå Kh√¥ng | $3‚Äì$15/1M | üê¢ Trung b√¨nh | ‚≠ê‚≠ê‚≠ê‚≠ê‚≠ê Xu·∫•t s·∫Øc | Reasoning t·ªët |
| **Ollama** | ‚úÖ Mi·ªÖn ph√≠ | N/A | üê¢ Ph·ª• thu·ªôc GPU | ‚≠ê‚≠ê‚≠ê OK | Self-hosted |

---

## Khuy·∫øn ngh·ªã cu·ªëi c√πng

1. **B·∫Øt ƒë·∫ßu**: d√πng **Groq** (mi·ªÖn ph√≠, nhanh, ƒë·ªß t·ªët)
2. **N√¢ng cao**: d√πng **DeepSeek** (r·∫ª nh·∫•t, ch·∫•t l∆∞·ª£ng cao)
3. **Production**: d√πng **OpenAI GPT-4o-mini** ho·∫∑c **Claude 3.5 Sonnet**
4. **Self-hosted**: d√πng **Ollama** v·ªõi Llama 3.1 8B (c·∫ßn GPU)

**L∆∞u √Ω**: B·∫°n c√≥ th·ªÉ c·∫•u h√¨nh nhi·ªÅu providers c√πng l√∫c v√† ch·ªçn trong UI c·ªßa Perplexica.


